
%---------------------------------------------------------------------
%
%                          Capítulo 4
%
%---------------------------------------------------------------------

\chapter{Desarrollo Del Proyecto}



\label{cap5:sec:Desarrollo Del Proyecto}
Una vez elegida la tecnología y las plataformas que se van a utilizar, se empieza a preparar el desarrollo del proyecto. En este capitulo se explicará que librerías y paquete de \texttt{Unity} se necesitan para tener una buena conexión con \texttt{Kinect} y, además, que información obtenida del sensor de movimiento podemos aprovechar para el proyecto. Después de esta aclaración, se expondrá como grabar y reproducir los movimientos del usuario captado, analizando los datos ofrecidos por el sensor de \texttt{Kinect}.

En la siguiente sección se especificará el proceso realizado para la comparación de los movimientos capturados, de modo que, el usuario obtendrá una respuesta concisa. Para ofrecer una aplicación dinámica y que el usuario reciba un \textit{feedback} gestual, se ilustra como se diseña e implementan avatares con animaciones en \texttt{Unity}.

De forma sucesiva, se describe el diseño de los escenarios 3D para ubicar a los avatares principales y secundarios de la aplicación. De este modo se han diseñado dos escenarios, uno para el entrenamiento del usuario y otro para reproducir el movimiento a realizar.

En el apartado posterior, se describe una manera de acabar la comparación del movimiento de forma más completa. Ofreciendo así, un análisis de cada parte del cuerpo describiendo el modo de corregir el movimiento.

Posteriormente se elaboran una serie de escenas en \texttt{Unity} que servirán de interfaz para la aplicación. En las diferentes escenas se encuentran la de inicio, el menú principal, ayuda, créditos, etc, y para cada una de ellas, se ha creado un entorno diferenciado según las necesidades dadas.
 
Y por último, una vez acabada la funcionalidad de la aplicación, se realizan la grabaciones de los movimientos con los profesionales de la escuela \texttt{Abadá-Capoeira}. Elaborando así, una batería de pruebas para seleccionar y ajustar el movimiento más preciso. 


%-------------------------------------------------------------------
\section{Paquetes para Unity}

\label{cap5:sec:Paquetes para Unity}
El primer paquete que se prueba es el que nos ofrece \texttt{Microsoft}\footnote{https://developer.microsoft.com/es-es/windows/kinect/tools}, que es un paquete destinado principalmente para \texttt{UnityPro}.\footnote{Unity profesional de pago con mas funcionalidad que \texttt{Unity} personal.} Al añadir este primer paquete al proyecto se empieza a manifestar una serie de errores de \textit{scripts}, y esto es debido a la incongruencia de versiones de \texttt{Unity}. El proyecto se desarrolla en \texttt{Unity Personal}, que es una versión gratuita de \texttt{Unity} , mientras que el paquete que ofrece \texttt{Microsoft} esta especificado para \texttt{Unity Pro}. Aun así, se corrigen errores de comandos y llamadas a funciones obsoletas para ver si se puede aprovechar este paquete.

En una primera instancia se ejecuta la escena que viene como ejemplo en el paquete de \texttt{Unity}, observando un comportamiento de funcionamiento intermitente, es decir, cuando nos colocamos enfrente de la cámara de \texttt{Kinect} a veces mostraba un esqueleto verde que emulaba la persona captada y otras veces dejaba de funcionar sin saber el error producido.
Debatiendo e intentando comprender si estos errores se producían por conexión de \texttt{kinect} o por funcionamiento incorrecto de la librería que nos ofrecía \texttt{Microsoft}, se opto por la opción de descartar este paquete para evitar futuras incompatibilidades y frustraciones.

Después de descartar el paquete que nos ofrecía \texttt{Microsoft} se decidió buscar en el \texttt{Assets Store de Unity}. Encontramos el paquete \texttt {Kinect v2 Examples with MS-SDK}\footnote{https://www.assetstore.unity3d.com/en/\#!/content/18708} que se eligió por su valoración positiva y también por la escasez de paquetes relacionados con \texttt{Kinect v2}.

Este paquete tiene todo lo necesario para reconocer la conectividad de \texttt{Kinect} y para poder utilizar los datos obtenidos del sensor. En una primera toma, la librería nos ofrece una serie de ejemplos básicos para poder comprender mejor el funcionamiento de \texttt{Kinect}. A su vez, es necesaria la instalación de \texttt{Kinect SDK 2.0} porque trae incorporados los drivers inprescindibles para la detección de la \texttt{Kinect v2}.


Los ejemplos que tiene implementado el paquete de \texttt{kinect  v2 Examples with MS-SDK} son variados:
\begin{itemize}
	\item \textit{AvatarsDemo}, simulador que muestra un avatar en tercera persona que correspondería a la persona captada y se puede controlar sobre el escenario 3D.
	\item \textit{BackgroundRemovalDemo}, son ejemplos que cambian el fondo que se encuentra detrás del usuario captado.
	\item \textit{ColliderDemo}, una serie de ejemplos para ver el funcionamiento de colisiones del usuario captado con los objetos que aparecen en la escena.
	\item \textit{FaceTrackingDemo}, este ejemplo reconoce la dirección de tu cabeza para girar la cámara de la imagen para simular la vista humana.
	\item \textit{FittingRoomDemo}, este ejemplo te da la opción de ponerte ropa encima de tu imagen real captada.
	\item \textit{GesturesDemo}, serie de ejemplos de funcionamiento de los gestos de kinect.
	\item \textit{InteractionDemo}, este ejemplo muestra como el usuario puede girar,rotar y agrandar un objeto con el movimiento de sus manos.
	\item \textit{KinectDataServer}, implementa un servidor de datos para guardar información como gestos de kinect.
	\item \textit{MovieSequenceDemo}, este ejemplo mostrará como reproducir un conjunto de frames de película con el cuerpo del usuario.
	\item \textit{MultiSceneDemo}, este ejemplo concatenará diferentes escenas de Unity basadas en las componentes de este paquete.
	\item \textit{OverlayDemo}, son tres ejemplos que muestras como interactuar con los objetos de la escena, para ello, se basa en el movimientos de los brazos y manos para hacer que los objetos se mueven, roten y se desplazen.
	\item \textit{PhysicsDemo}, muestra una simulación de físicas que capta el movimiento del brazo para lanzar una pelota virtual.
	\item \textit{RecorderDemo}, ejemplo que muestra como grabar y reproducir un movimiento captado por kinect.
	\item \textit{SpeechRecognitionDemo}, ejemplo que sirve para realizar acciones por comandos por voz, aunque se producen errores cuando se probó este ejemplo.
	\item \textit{VariousDemos}, implementa dos ejemplos, como pintar en el aire moviendo los brazos y el otro dibuja bolas verdes que se colocan en tus articulaciones simulado un esqueleto.
	\item \textit{VisualizerDemo}, este ejemplo convierte la escena, según lo ve el sensor, en una malla y la superpone sobre la imagen de la cámara.\\	
\end{itemize}
Una vez explicado los ejemplos, elegimos cual de ellos podríamos utilizar para aprovechar su funcionalidad y tener un apoyo base para el desarrollo del proyecto. Los ejemplos seleccionados serían el \texttt {AvatarsDemo, GestureDemo y RecorderDemo}. Más adelante se explica con mas detalle que se utiliza de estos ejemplos.\\

\section{Grabar y reproducir movimientos de Usuario}

\label{cap5:sec:Grabar y reproducir movimientos de Usuario}

Como el objetivo principal de este proyecto es el entrenamiento de actividades físicas, se selecciona como ejemplo de primer estudio, el \texttt{Recorderdemo} por su potencial para guardar y reproducir un movimiento.


\subsection{Investigación base}

En una primera vista se muestra como \texttt{Kinect} capta al usuario, esta representación se hace mediante un \textit{cubeman}\footnote{Esqueleto verde que emula el movimiento de la persona captada.} que simula todo el movimiento que realiza el usuario.

Esta figura se crea gracias al \textit{script} de \texttt{Cubeman Controller}, el cual se inicializa con el número del cuerpo que se quiere mostrar, siendo seis las personas que pueden ser detectadas por \texttt{Kinect v2}, y ofreciendo además, la opción de representar el \textit{cubeman} en modo espejo. Los datos del \textit{cubeman} (ver Figura \ref{fig:doscamarasbase}) están definidos con 25 \texttt{GameObjects} llamados \texttt{Joints}, que hacen una representación de las articulaciones del cuerpo humano. Estos \texttt{Joints} se representan en \texttt{Unity} con unas coordenadas (X,Y,Z) junto a su rotación, siendo obtenida toda esta información a través del sensor de \texttt{Kinect}.
Los 25 \texttt{Joints} serían : cadera central y laterales , pecho, clavícula, cuello, cabeza, hombros, codos, muñecas, pulgares, manos centrales, rodillas, tobillos y pies.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.94\linewidth]{Imagenes/Capitulos/capitulo5/Avatar-controller-joints}
	\caption{Cubeman con la lista de todos los Joints}
	\label{fig:doscamarasbase}
\end{figure}

\vspace{5cm}
Para hacer una representación correcta del esqueleto y que se mueva como una entidad, el \textit{script} \texttt{Cubeman Controller} pone la posición del \texttt{Joint} de la cadera base como la posición y rotación del objeto padre, y de esta manera, todos los demás joint serán hijos de este \texttt{GameObjects}. Para calcular la posición relativa  de todos los \texttt{Joints}, se resta la posición del padre con la posición de cada \texttt{Joint} dada por el \texttt{\texttt{Kinect} Manager}.

El \textit{script} \texttt{\texttt{Kinect} Manager} es un \texttt{Singleton}\footnote{Es un patrón que consiste en que existe una única instancia y es la propia clase la responsable de crear la única instancia. Permite el acceso global a dicha instancia mediante un método de clase} encargado de la comunicación entre el sensor de \texttt{Kinect} y las aplicaciones de Unity.(véase Figura \ref{fig:singleton})

\begin{figure}[th!]
	\centering
	\includegraphics[width=0.7\linewidth]{Imagenes/Capitulos/capitulo5/singleton}
	\caption{Patrón de Singleton}
	\label{fig:singleton}
\end{figure}

Este \textit{script}, al ser común a todos los ejemplos nombrados anteriormente, implementa todas las funciones y comunicaciones necesarias para su funcionamiento, pero en este caso, se investiga como obtiene la información que le envía al \texttt{cubeman Controller}.

\texttt{\texttt{Kinect} Manager} se encarga de analizar la información del \texttt{SensorData}, siendo este, una estructura de datos ofrecida por el \textit{script} \texttt{\texttt{Kinect}Interop}\footnote{\textit{script} encargado de tener comunicación directa con el sensor de la \texttt{Kinect}} donde aparece la información de la imagen, pronfundidad, color y datos de los usuarios captado con el sensor. Los datos de los usuarios captados se encapsulan en el \texttt{BodyDataFrame}, esta estructura a vez, contiene la información del número de usuarios captados, su identificador, la información de los \texttt{BodyData}\footnote{Información de los joint de un cuerpo especifico}, etc.

Una vez comprendido el \texttt{SensorData} se observa como el \texttt{\texttt{Kinect} Manager}, analizando el \texttt{BodyDataFrame}, va actualizando y asignando a cada usuario el identificador correspondiente
de un  \texttt{BodyData} en todo momento, y este a su vez, va pasando al \texttt{Cubeman Controller} esta información para que reproduzca el movimiento.

Otro \textit{script} que se debe mencionar es el \texttt{\texttt{Kinect}RecorderPlayer}, que es el encargado de guardar y reproducir un movimiento a partir de un fichero de texto. La información se le pide al \texttt{\texttt{Kinect} Manager}, y este la obtiene del \texttt{\texttt{Kinect}Interop} devolviéndola en una cadena de caracteres. Esta cadena hace referencia a un \textit{frame}\footnote{Es un fotograma, \texttt{Unity} por defecto reproduce a 60 \textit{frames} por segundo } que tiene la información del instante de tiempo, los \textit{BodyData} captados y las coordenadas (X,Y,Z) respecto al mundo de todos sus \texttt{Joints}. Los \textit{BodyData} captados aparece primero su identificador y después sus 25 \texttt{Joints}, mientras que los \textit{BodyData} no captados aparecerá un cero (Figura \ref{fig:ejemplo_txt}).
\texttt{KinecRecorderPlayer} también discierne entre grabación y reproducción activando solo una de la dos a la vez.

\begin{figure}[th!]
	\centering
	\includegraphics[width=1\linewidth]{Imagenes/Capitulos/capitulo5/ejemplo_txt}
	\caption{Fichero de texto con los datos del BodyData}
	\label{fig:ejemplo_txt}
\end{figure}

\subsection{Implementacion de la Grabación y reprodución de los movimientos }

Después de haber realizado la investigación y compresión del material que se puede aprovechar para grabar y reproducir un movimiento, se plantearon una serie de desafíos e implementaciones que se deben realizar.

En primer lugar se implementó la forma de poder reproducir un movimiento grabado a la vez que muestra al usuario captado en tiempo real, para ello, se creó una función llamada \texttt{SetBodyFrameFromCsvAndPoll} en el \texttt{\texttt{Kinect}Interop}. El funcionamiento de esta función es el de obtener primero el \texttt{SensorData} con los datos del usuario captados por la \texttt{Kinect} y después, se busca un \texttt{BodyData} que esté libre de ese mismo \texttt{SensorData}, para poder así, rellenarlo con los datos del fichero de texto. También se añadió un campo más a la estructura de \texttt{BodyData} para saber si los datos son procedentes del sensor o de un fichero de texto. 
Posteriormente de hacer estos cambios, se realizó una modificación en el \textit{script} \texttt{Cubeman Controller} para poder escoger si los datos proceden del sensor o de un fichero texto.

Con todas estas mejoras implementadas, se empezó a modificar el escenario de \texttt{Unity} para mostrar dos cámaras. La primera cámara enfoca un escenario donde se encuentra el \textit{cubeman} que representa al usuario captado por el sensor de \texttt{Kinect}, mientras que la segunda cámara, muestra otro escenario colocado en la esquina superior derecha , y ubicando dentro del mismo, otro \textit{cubeman} que está a la espera de reproducir el movimiento guardado en un fichero de texto(Figura \ref{fig:dos_camaras}).


\begin{figure}[th!]
	\centering
	\includegraphics[width=0.92\linewidth]{Imagenes/Capitulos/capitulo5/doscamarasbase}
	\caption{Escena con los dos cubeman}
	\label{fig:dos_camaras}
\end{figure}
\section{Comparación de los movimientos de Usuario}

Otra etapa en el desarrollo de este proyecto se trata de comparar un movimiento grabado con el que esté realizando el usuario.

\subsection{Investigación base} 

La primera forma de comparar un movimiento en la que se debatió, fue la de estudiar las trayectorias de cada movimiento, calculando así, la gráfica que generaban las coordenadas de los \texttt{Joints} a lo largo del tiempo y determinar la pendiente. Esta forma de comparación era muy especifica y laboriosa para cada movimiento, por lo que se intento tener otro camino para hacer la comparación de forma más genérica.

Con esta idea en mente ,se estudió el ejemplo de \texttt{GestureDemo} que reconoce gestos del usuario para rotar y hacer \textit{zoom} sobre un cubo. Para que reconozca estos gestos previamente, hay que añadirlos a las lista de gestos del \textit{script} \texttt{\texttt{Kinect}Gesture} e implementar su funcionalidad en el método \textit{CheckForGesture}. Posteriormente hay que notificar al \texttt{\texttt{Kinect}Manager} que gesto de los registrados se quiere detectar.

En cuanto a la funcionalidad del gesto, se realiza por estados y progresión,  permaneciendo en el primer estado hasta que identifique una posición especifica. Para completar el gesto se tendrá un tiempo determinado para llegar a la progresión final del movimiento, sino el gesto se cancelará.


\subsection{Implementación de la comparación de los movimientos}

Una vez analizado la funcionalidad de los gestos de \texttt{Kinect}, se apoyó en esa idea para implemenentar la comparación del movimiento como un gesto de \texttt{Kinect}. Para empezar de añadió el gesto al \texttt{\texttt{Kinect}Gesture} con el nombre \texttt{Move}, acto seguido, se implementó la funcionalidad en \texttt{CheckForGesture} haciendo que tenga dos estados. El estado cero se encarga de calibrar la posición inicial ,dando al usuario, la oportunidad de colocarse en esa posición y ofreciéndole un margen de tres segundos para que se prepare. 

Para el siguiente estado hay que explicar antes, que la información del movimiento esta guardada previamente en una lista de \textit{strings} y cada elemento corresponde a un \textit{frame}. 
Después de este inciso, se define el siguiente estado como el estado por defecto ,y es así,  porque engloba todos los siguiente estados al cero. El número del estado será utilizado para acceder y obtener el \textit{frame} de la lista del movimiento. En este momento se decidió que para que sea más eficiente la transición de estados, se incrementa en más de una unidad, ahorrándose así comparaciones innecesarias, ya que la comparación de dos \textit{frames} consecutivos es muy similar. Para pasar al siguiente estado habrá una equiparación de cada uno de los  25 \texttt{Joints} del usuario con los \texttt{Joints} del \textit{frame} correspondiente. La comparación consiste en igualar las coordenadas (X, Y, Z) con un margen de error modificable por el usuario, si cumple este requisito pasará al siguiente estado. La comparación tiene un tiempo límite que será el tiempo del movimiento más dos segundos de espera, en ese tiempo el usuario deberá superar todos los estados para que el movimiento sea realizado correctamente, en caso contrario fracasará y se cancelará el gesto (Figura \ref{fig:grafo_movimiento}). El resultado del gesto se muestra por pantalla para dar un \textit{feedback} inmediato al usuario. 

\begin{figure}[th!]
	\centering
	\includegraphics[width=0.92\linewidth]{Imagenes/Capitulos/capitulo5/diagrama_movimiento}
	\caption{Grafo de comparación de movimiento}
	\label{fig:grafo_movimiento}
\end{figure}

\section{Creación de avatares y animaciones}

En esta etapa del proyecto, se han desarrollado los diferentes avatares con una estética humana. Con el objetivo de dar una sensación mas realista a los \textit{cubeman} y de este modo, proporcionar una perspectiva mas amena al usuario.

\subsection{Investigación base} 


La primera aplicación que se utilizó para crear los personajes que darían vida al proyecto fue \texttt{MakeHuman}, ya que mostraba una interfaz amigable e intuitiva (ver Figura \ref{fig:makehuman_avatar} ). El primer avatar utilizado fue simple, ya que al principio interesaba ver el resultado que proporcionaba el personaje junto con el \textit{cubeman} y de esta forma determinar la configuración de los huesos que mas se ajustaba a las necesidades dadas. Para comprobar que esqueleto se debía emplear,se tuvieron que crear cuatro avatares diferentes, con 31, 163, 137 (ver Figura \ref{fig:makehuman_avatar_huesos3} )  y 53 huesos respectivamente.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.92\linewidth, height=0.4\textheight]{Imagenes/Capitulos/capitulo5/makehuman_avatar}
	\caption{Avatar inicial de MakeHuman}
	\label{fig:makehuman_avatar}
\end{figure}

Después de realizar varias pruebas, se determinó que el avatar que mejor se adaptaba a los movimientos capturados por \textit{Kinect} era \textit{Default no toes} ver Figura \ref{fig:makehuman_avatar_huesos3} ). Este personaje poseía 137 huesos, de los cuales 25 serían utilizados por el \textit{cubeman}.

\begin{figure}[p!]
	\centering
	\includegraphics[width=0.92\linewidth, height=0.37\textheight]{Imagenes/Capitulos/capitulo5/makehuman_avatar_huesos3}
	\caption{Avatar con 137 huesos}
	\label{fig:makehuman_avatar_huesos3}
\end{figure}


Para comprobar como se visualizaban los movimientos de un avatar con ropa, se utilizó el personaje inicial vestido con un peto y una camiseta (ver Figura \ref{fig:makehuman_avatar2} ). Al observar de los movimientos capturados con \texttt{Kinect} que las texturas de la piel y la ropa no plasmaban un realismo razonable, se optó por buscar otro software que ayudase a realizar esa tarea.


\begin{figure}[p!]
	\centering
	\includegraphics[width=0.92\linewidth, height=0.4\textheight]{Imagenes/Capitulos/capitulo5/makehuman_avatar2}
	\caption{Avatar inicial con ropa}
	\label{fig:makehuman_avatar2}
\end{figure}

En la búsqueda se encontraron aplicaciones dedicadas al modelado de personajes 3D como \texttt{Blender}, pero con una curva de aprendizaje demasiado larga para las necesidades dadas. También se examino una aplicación llamada \texttt{MarvelousDesigner} la cual se emplea para desarrollar prendas de vestir. El problema surgía cuando se intentaba importar el avatar creado con \texttt{MakeHuman}, ya que no eran compatibles los formatos de las dos aplicaciones y por lo tanto se descartó seguir por esa vía. En el camino se observó que existía una compañía llamada \texttt{Mixamo} que ofrecía una aplicación para el desarrollo de avatares y a su vez, un entorno dedicado a la animación de los personajes creados. Por este motivo, se tomó la decisión de cambiar a \texttt{Fuse Character Creator de Mixamo} como aplicación para el desarrollo de los personajes, ya que se amoldaba perfectamente a las necesidades de este proyecto.

\subsection{Implementación de los avatares y animaciones}


A fin de realizar un entorno mas realista, se crearon tres avatares diferentes, cada uno con una estética propia. A la hora de elaborar el vestuario de los personajes, se observó la ropa que utilizan los integrantes de la escuela \texttt{Abadá-Capoeira} para tener un modelo a seguir. Se trata de un pantalón largo y una camiseta de tirantes en color blanco con el logo de la escuela. 

Con el propósito de crear una ropa muy similar a la utilizada por la escuela  \texttt{Abadá-Capoeira}, se usaron prendas prediseñadas en la aplicación \texttt{Fuse Character Creator} como los pantalones, camisetas y el top que utilizarían los avatares del sistema con los retoques apropiados para darle ese color blanco característico.

Los dos avatares principales, como son el alumno y el profesor se desarrollaron con la misma vestimenta que utiliza la escuela \texttt{Abadá-Capoeira}, en cambio los dos avatares que se emplean para dar un mayor dinamismo a la aplicación utilizan el mismo pantalón largo, mientras que el avatar masculino no utilizará prenda superior y el avatar femenino vestirá un top en color blanco.

Tras completar la estética de los personajes, \texttt{Fuse Character Creator de Mixamo} ofrece la posibilidad de configurar los huesos de los avatares para posteriormente utilizar las animaciones que suministra \texttt{Mixamo}. Para ello será necesario subir a los servidores de \texttt{Mixamo} dichos personajes y cuando se complete el proceso, la aplicación redirigirá su actividad al navegador web. Como ocurría con \texttt{MakeHuman}, \texttt{Mixamo} ofrece la posibilidad de crear varios esqueletos para un mismo personaje, en este caso se presentan cuatro casos con 25, 41 (ver Figura \ref{fig:mixamo-rig}), 49 y 65 huesos respectivamente.

\begin{figure}[t!]
	\centering
	\includegraphics[width=0.7\linewidth, height=0.4\textheight]{Imagenes/Capitulos/capitulo5/mixamo-rig}
	\caption{Auto-Rig de Mixamo}
	\label{fig:mixamo-rig}
\end{figure}

Una vez comprendida la generación de avatares. El avatar elegido que mejor se adapta a \texttt{Kinect} es el que contiene 41 huesos, ya que demuestra una movilidad más semejante al \textit{cubeman} inicial.

Con el propósito de utilizar las animaciones que suministra \texttt{Mixamo} se observó el ejemplo \texttt{AvataresDemo}, el cual utiliza un script \texttt{AvatarController} que realiza una conexión entre los \textit{joints} y los huesos incorporados en el avatar. 

Posteriormente para que los avatares no se queden en una posición estática, se incorporaron las animaciones de la ginga, victoria y derrota, obteniendo así, un \textit{feedback} más ilustrado de la comparación del movimiento.

Para incorporar las animaciones al avatar, se crea el componente \texttt{Animator Controller} de \textit{Unity}, encargado de añadir y gestionar animaciones. Este componente contiene una máquina de estados capaz de coordinar la animación que se ejecuta en cada momento. El estado inicial será la \textit{ginga} y se realizará una transición a la animación de victoria o derrota, que dependerá en todo caso, de la comparación del movimiento por parte del usuario con el del profesor. Una vez determinado el estado, este volverá a la animación de \textit{ginga} para continuar con el siguiente movimiento (ver Figura \ref{fig:animator}).

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth, height=0.4\textheight]{Imagenes/Capitulos/capitulo5/animator}
	\caption{Diagrama de estados de animator}
	\label{fig:animator}
\end{figure}


Se constató que existía un conflicto entre el \texttt{Animator Controller} y el \texttt{AvatarController} dando lugar a un lucha por quien tiene el control del avatar. Por ello, se implementó un \textit{script} que desactiva el componente \texttt{Animator Controller} cuando el sensor de \textit{kinect} detecta al usuario y se vuelve a activar cuando el usuario se sale de la escena.


\section{Análisis de los movimientos del Usuario}

Una parte importante de este proyecto consiste en dar una corrección del movimiento, el cual, el usuario esta imitando en tiempo real. En esta sección se explicará como se implementó este análisis.

\subsection{Investigación base}

Para este apartado se observó el desarrollo de la comparación de movimiento implementada anteriormente. Esa sección respondía al usuario dándole un \textit{feedback} inmediato si había realizado el movimiento correctamente o incorrecta, sin embargo , no le detallaba que partes del cuerpo había colocado de manera errónea. 

El planteamiento del análisis comienza reproduciendo el movimiento del avatar del usuario junto al avatar de la grabación, deteniéndose ,si llegara el caso,  en el \textit{frame} donde el usuario cometió el error. En ese instante cambiará los huesos del avatar controlado por el usuario a un color rojo, en consecuencia de una colocación incorrecta del hueso. Adicionalmente mostrará un panel con un texto describiendo las correcciones que se deben aplicar. Esta información se compondrá de la parte del cuerpo que se está analizando , añadiendo consecutivamente, la dirección, la profundidad y la altura que servirán de pautas para que el usuario corrija su posición.

\subsection{Implementación del análisis de los movimientos}
Una vez planteada las especificaciones del análisis se empieza con  su implementación. Primero se creó un \textit{script} llamado \texttt{Registrar\_movimientos}, el cual, guarda toda la información del movimiento hasta donde el usuario comete el error. Esta información contiene el estado\footnote{Corresponde al frame que se esta comparando.} donde se produce la equivocación y los datos de los \texttt{Joints} pertenecientes a los avatares.
Posteriormente se necesitó hacer una modificación funcional en el gesto \texttt{Move} de \texttt{\texttt{Kinect}Gesture}, para conseguir de esta manera, rellenar esa información en cada comparación. Esta modificación consiste en enviar la información del estado y los \textit{joints} de los avatares al \texttt{Registrar\_movimientos}, una vez superada la comparación de ese \textit{frame}. Gracias a esta lógica, se quedará registrado la traza del movimiento hasta que el usuario se equivoque.

A partir de este momento para poder mostrar la información recogida, se implementó una funcionalidad nueva en el \textit{script} \texttt{Registrar\_movimientos}. Esta característica consiste en desplazar los avatares a primera escena, modificando los materiales para que se vean transparentes ,y crear así, un esqueleto verde parecido a los \textit{cubeman} del principio. Estos avatares simulan el movimiento hasta el \textit{frame} donde se equivocó el usuario, y en este último estado, realiza una comprobación de cada \texttt{Joint} para cambiar el hueso, si ha fallado, de color de verde a rojo. A la vez, se va generando un \textit{string} con una corrección de posicionamiento compuesto por cuatro partes. Para la primera pieza se creó un diccionario que, basándose en el número del \texttt{Joint}, devuelve en palabras la parte del cuerpo correspondiente. En la implementación de este diccionario se han agrupado \texttt{Joints} dispares, ya que siendo diferentes forman una misma parte del cuerpo, como por ejemplo las manos que la forman tres \texttt{Joints}. La segunda pieza del \textit{string} está formada por la elección de la dirección,  y esta se comprueba, realizando la diferencia de la coordenadas X del \texttt{Joint} del usuario con la del \texttt{Joint} de la grabación. Si la diferencia es positiva la dirección será hacia la derecha, en caso contrario será hacia la izquierda. Seguidamente para la tercera pieza del \textit{string}, se realiza la diferencia con la coordenada Z definiendo así la profundidad. Si la diferencia es positiva la profundidad será hacia atrás , en caso contrario hacia delante. Y para la cuarta pieza del \textit{string}, se efectúa la distinción con la coordenada Y, definiendo así la altura. Si la diferencia es positiva la altura será definida de forma descendente, en caso contrario ascendente.
Esta lista de correcciones se mostrará en un panel una vez completada evitando los \textit{strings} repetidos, a su vez, se añaden colores a cada una de las piezas del \textit{string}, ofreciendo de esta manera un texto menos plano y mas legible (ver Figura \ref{fig:analisis_movimiento}) 



\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth, height=0.34\textheight]{Imagenes/Capitulos/capitulo5/analisis_movimiento}
	\caption{Análisis de movimiento}
	\label{fig:analisis_movimiento}
\end{figure}


\section{Creación de los escenarios 3D}

Con el objetivo de conseguir un ambiente más realista y dinámico, se elaboraron dos escenarios diferentes, ambientados cada uno de ellos según su propósito. El primero de ellos escenifica un entorno para el alumno donde realizará el entrenamiento, como es el caso de un gimnasio. El segundo, está orientado hacia el profesor y los animadores, representando una playa Brasileña.


\subsection{Escenario del gimnasio}

La creación del escenario del gimnasio se diseñó a partir de diferentes componentes,  distribuidos en distintos paquetes y obtenidos en el \texttt{Asset} \texttt{Store} de \texttt{Unity}. En el diseño de suelo se creó un \texttt{Gameobject} de tipo panel y  se le incrustó un material, dispuesto por el paquete \texttt{Yughues Free Wooden Floor Materials}\footnote{https://www.assetstore.unity3d.com/en/\#!/content/13213}, para simular un suelo de madera. En la construcción de las paredes del escenario se crearon tres paneles, colocándoles de forma vertical formando un cubo abierto, y además se añadió a todos los paneles, un material del paquete \texttt{18 High Resolution Wall  Textures}\footnote{https://www.assetstore.unity3d.com/en/\#!/content/12567} que se asemejan a una textura tipo piedra. Se colocan unos bancos y un casillero para dar una sensación de sala de entrenamiento, estos objetos son modelos del paquete \texttt{Locker Room Props}\footnote{https://www.assetstore.unity3d.com/en/\#!/content/3355}. Para no dar una impresión de una habitación cerrada se añadieron dos ventanas y un ventilador , estos objetos vienen implementados en el paquete \texttt{Props for the Classroom}\footnote{https://www.assetstore.unity3d.com/en/\#!/content/5977},a su vez, se observó también que en el mismo paquete venía implementado un objeto con la forma de una pizarra de clase, entonces para agregar una huella educativa se añadió este elemento a escena.

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth, height=0.4\textheight]{Imagenes/Capitulos/capitulo5/escenario1}
	\caption{Escenario de gimnasio}
	\label{fig:primer-escenario}
\end{figure}

\subsection{Escenario de la isla}

Para la creación de este escenario, y con la misión de realizar un entorno ambientado en las playas brasileñas, se realizó una investigación previa sobre los paquetes existentes que cumplian estas características. Se descartaron varias opciones de pago, ya que algunos no cumplian con las particularidades buscadas y otros tenían un coste demasiado elevado. Por lo tanto, tras esta decisión, se optó por usar el paquete gratuito \texttt{Island Assets}\footnote{https://www.assetstore.unity3d.com/en/\#!/content/56989}
obtenido en el \texttt{Asset} \texttt{Store} de \texttt{Unity}, de modo que junto al profesor y los animadores, este escenario simulase la sensación de estar en una playa brasileña. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.99\linewidth, height=0.32\textheight]{Imagenes/Capitulos/4/escenario_isla}
	\caption{Escenario para el profesor y los animadores}
	\label{fig:escenario_isla}
\end{figure}


Posteriormente, se hicieron una serie de modificaciones para que el paquete \texttt{Island Assets} tuviera un aspecto acorde con el proyecto a desarrollar. Lo primero que se hizo fue quitar el componente \textit{Treasure chest}(cofre) ya que desentonaba demasiado con la temática del entorno deseado. En segundo lugar se desactivó el componente \textit{Dock}(Embarcadero) puesto que no sería necesaria su utilización debido a la falta de barcos navegando. Por último, el paquete de \texttt{Unity} venía predefinido con tres palmeras, dando una sensación de isla desierta. De modo que, se añadieron como componente del terreno, más de una decena de palmeras en tamaños aleatorios, intentando dar un efecto de isla habitada (véase Figura \ref{fig:escenario_isla}). Con todo ello, el paquete \texttt{Island Assets} de \texttt{Unity} ha servido como escenario para simular una playa brasileña.


\section{Grabacion de movimientos con gente experta}

En esta etapa del proyecto se visitó la Asociación Cultural Deportiva Rio\footnote{https://www.asociacionrio.com/}, donde se reúnen los practicantes expertos en capoeira, para realizar una serie de grabaciones y pruebas.

\subsection{Movimientos grabados}
Este proceso consistía en grabar una batería de movimientos de capoeira \cite{capoeira2007little} para seleccionar los captados correctamente por \texttt{Kinect}. Para facilitar la grabación al profesor de capoeira, se optó por capturar varias repeticiones del mismo movimiento en la misma grabación. De este modo, y con la supervisión del profesor, se registraron 20 técnicas de capoeira:
\begin{itemize}
	\item \textit{Ginga}, es la técnica fundamental de la capoeira, consiste en realizar un movimiento constante que prepara al usuario para acciones como evadir, fintar o atacar, así como conservar el impulso. La forma general de la ginga es un continuo paso triangular, retrocediendo un pie y luego con el otro en diagonal mientras se mantiene las piernas separadas. Para este movimiento se realizaron tres grabaciones diferentes porque es un movimiento que puede tener diversas variantes.
	\item \textit{Aú}, movimiento que consiste en dar una voltereta lateral.
	\item \textit{Armada}, técnica en donde el usuario gira sobre si mismo en vertical golpeando con el talón al oponente.
	\item \textit{Queixada}, movimiento que consiste en dar un paso quedándose de costado al oponente y se realiza una patada con un movimiento circular.
	\item \textit{Bênção}, técnica que que se ejecuta con una patada frontal básica, realizada contra el abdomen o el pecho del oponente.
	\item \textit{Chapa-Pisào}, movimiento similar al Bênção pero se realiza con la planta del pie y paralelo al suelo.
	\item \textit{Gancho}, técnica que consiste en levantar la pierna en un diagonal hasta una posición alta, para después contraer la rodilla  y golpear con el talón en dirección descendente.
	\item \textit{Martelo}, movimiento de patada que tiene como objetivo golpear con el empeine en la sien del oponente.
	\item \textit{Meia Lua de Compasso}, técnica que consiste en apoyar una mano en el suelo mientras se gira 180º y se lanza la pierna opuesta en un movimiento circular y ascendente, para golpear con el talón en la cabeza del oponente.  
	\item \textit{Meia Lua de Frente}, movimiento que realiza una patada frontal de fuera a dentro
	\item \textit{Ponteira}, movimiento que consiste en estirar la pierna hacia el oponente y golpearlo con la punta del pie.
	\item \textit{Joelhada}, movimiento que se realiza alzando la rodilla hacia delante con la intención de golpear.
	\item \textit{Galopante}, técnica que realiza un golpe con la mano abierta parecido a una bofetada.
	\item \textit{Telefone}, técnica que sirve para golpear con las dos manos en los tímpanos del oponente.
	\item \textit{Despreço}, movimiento que consiste en dar una bofeta pero con la parte externa de la mano.
	\item \textit{Skada}, movimiento que consisten en lanzar golpes consecutivos hacia delante con la mano abierta.
	\item \textit{Esquiva de frente}, es un técnica para esquivar un ataque elevado y consiste en desplazar el cuerpo hacia abajo.
	\item \textit{Negativa}, es una posición defensiva utilizado para esquivar o para desplazarse por el suelo.


\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth, height=0.7\textheight]{Imagenes/Capitulos/capitulo5/grabacion_movimiento}
	\caption{Realizando las grabaciones de movimiento}
	\label{fig:grabación_movimiento}
\end{figure}
	
\end{itemize}


\subsection{Elección y ajuste de los movimientos}
Después del proceso de grabación ,se tuvieron que seleccionar los movimientos que mejor se asemejaban al real, recortando el intervalo de \textit{frames} más adecuado para incluirlo en la aplicación.
De los 20 movimientos grabados los seleccionados fueron :Bênção, Ginga, Joehjada, Escada, Galopante, Meia Lua de Frente, Chapa-Pisào y Punteira.
Estos 8 movimientos fueron factibles para su uso porque el resto, al incluir giros, presentaron problemas en la grabación. Esto se debe a que \texttt{Kinect} sólo posee una cámara frontal, de modo que al rotar alrededor del eje vertical se acaba perdiendo la referencia de cuáles son las extremidades izquierda y derecha. Como resultado, al darse la vuelta, la captura vuelve a mostrar al usuario de frente, pero con los brazos y las piernas cruzadas.

\section{Transición de las escenas}


En \texttt{Unity}, como se ha mencionado anteriormente, las escenas contienen los objetos del juego. Se pueden usar para crear un menú principal, animaciones, niveles, etc. En cada escena se ha creado un entorno diferenciado para cada una de las necesidades dadas.

Este entorno está pensado para ser utilizado por el alumno para que pueda aprender a realizar diferentes movimientos de capoeira sin la necesidad de que esté presente un profesor. El entrenamiento consiste en imitar una serie de movimientos, los cuales han sido previamente capturados por varios expertos en el arte marcial. El entrenamiento virtual se desarrolla acorde al nivel que posea el alumno, ya sea principiante, aprendiz o avanzado, de este modo, el alumno va aprendiendo a realizar los movimientos de forma progresiva.

\vspace{0.6cm}
Gracias a que el sistema compara \textit{frame} a \textit{frame} la posición del alumno con la del profesor virtual, este podrá realizar un análisis de las transiciones en las que está cometiendo algún error. 

Tras realizar una abstracción del flujo de ejecución que realiza el entrenador virtual entre las diferentes escenas, se muestra el diagrama de la lógica del sistema en la figura \ref{fig:diagram} 

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth, height=0.7\textheight]{Imagenes/Capitulos/6/Diagram}
	\caption{Diagrama que ilustra la lógica del sistema}
	\label{fig:diagram}
\end{figure}


\subsection{Escena de Inicio}

Se trata de la escena inicial del juego. Presenta una interfaz de tipo UI, la cual contiene el nombre de la aplicación y una breve descripción. Además se muestran los tres emblemas de las diferentes organizaciones presentes, como son la UCM, FDI y Abadá-Capoeira. (ver Figura \ref{fig:menu_inicio})

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth, height=0.4\textheight]{Imagenes/Capitulos/capitulo5/interfaz_inicio}
	\caption{Interfaz menu inicio}
	\label{fig:menu_inicio}
\end{figure}

\subsection{Escena de Menú Principal}

Tras pulsar el botón de inicio en la anterior escena, pasamos al menú principal, en el cual se puede decidir si se quiere empezar a entrenar, visualizar una ayuda sobre como utilizar la aplicación, los créditos o volver a la escena de inicio.(ver Figura \ref{fig:menu_principal})

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth, height=0.4\textheight]{Imagenes/Capitulos/capitulo5/Interfaz_menu_principal}
	\caption{Interfaz menu principal}
	\label{fig:menu_principal}
\end{figure}
\subsection{Escena de Ayuda}

Esta escena muestra varios mensajes de ayuda en los que se explica detalladamente el funcionamiento de la aplicación, además de como obtener un mayor rendimiento, ya que serán necesarias una pequeñas pautas para su utilización. También se resolverán las diferentes dudas que le puedan surgir al alumno.(ver Figura \ref{fig:interfaz_ayuda})


\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth, height=0.4\textheight]{Imagenes/Capitulos/capitulo5/Interfaz_ayuda}
	\caption{Interfaz de ayuda}
	\label{fig:interfaz_ayuda}
\end{figure}

\vspace{2cm}

\subsection{Escena de Créditos}

Al igual que en la escena de ayuda, solo se podrá acceder desde el menú principal. Se muestran los créditos sobre los desarrolladores, organismos implicados, agradecimientos y las licencias utilizadas en el proyecto.(ver Figura \ref{fig:creditos})

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth, height=0.4\textheight]{Imagenes/Capitulos/capitulo5/interfaz_creditos}
	\caption{Interfaz de créditos}
	\label{fig:creditos}
\end{figure}

\subsection{Escena de Profesor}

Cuando el usuario inicia el sistema como profesor, puede acceder a la funcionalidad de grabación de nuevos movimientos. Al comenzar a realizar la captura es necesario introducir el nombre deseado para el nuevo movimiento y colocarse a unos tres metros de \texttt{Kinect} para ser capturado correctamente. A partir de ese momento, el sistema graba los movimientos realizados por el usuario y los guarda en ficheros de texto para poder utilizarlos tanto para mostrárselos a los alumnos como para compararlos con los movimientos de estos cuando se encuentren practicando. Con el fin de de obtener una mayor inmersión en la aplicación, se utiliza el modo espejo como efecto para reproducir los movimientos captados. 

El profesor también puede utilizar la funcionalidad del alumno, ya que será necesario revisar y reproducir el correcto funcionamiento de los nuevos movimientos capturados con \texttt{Kinect}. Inicialmente, la aplicación incluye ocho movimientos capturados a instructores de la escuela \texttt{Abadá-Capoeira}.\footnote{http://www.abadacapoeira.com.br/}

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth, height=0.4\textheight]{Imagenes/Capitulos/capitulo5/interfaz_acesso}
	\caption{Interfaz para seleccionar tipo de usuario}
	\label{fig:tipo_usuario}
\end{figure}

\subsection{Escena de Alumno}

Si el usuario es un alumno, se entrará en la escena principal del proyecto, donde se desarrolla toda la funcionalidad del entrenamiento virtual. En el interior de la escena se muestra la misma interfaz que en el caso del profesor, con la diferencia de que este no podrá grabar movimientos para su posterior análisis.

Considerando que al comenzar a formarse en un arte marcial se desconocen los nombres de los movimientos que se desean poner en práctica, se le ofrece al alumno la posibilidad de visualizar previamente los movimientos antes de empezar la práctica para poder seleccionar más fácilmente el que desea. Para iniciar el entrenamiento acorde a su experiencia, el alumno tendrá que seleccionar el nivel que le corresponda, ya sea principiante, aprendiz o avanzado. 

Tras elegir el nivel, se pasará a la selección del movimiento que se quiere aprender o practicar, de este modo, el alumno podrá comenzar a entrenar acorde a su nivel. 

Posteriormente a la selección del movimiento, el alumno deberá iniciar la comparación mediante el botón correspondiente. Al pulsar sobre el botón, el alumno deberá adoptar una pose inicial correspondiente al movimiento seleccionado previamente. Hasta que el alumno no tome esa misma pose, el sistema estará esperando la calibración. En el instante en que la pose del alumno sea la misma que la del entrenador virtual, el sistema estará calibrado y empezará una cuenta atrás de tres segundos, tras la cual se empezará a reproducir el movimiento seleccionado. 

En el momento en que el entrenador virtual inicie una reproducción de un movimiento, el alumno deberá imitarlo lo más fielmente posible. Mientras se realizan las transiciones, el sistema comparará las posición de los 25 \textit{joints} que componen el esqueleto del entrenador virtual, con las posiciones de los 25 \textit{joints} correspondientes al alumno capturado por \texttt{Kinect}.

Tras finalizar el movimiento, el asistente mostrará una animación de éxito en el caso de que el movimiento se haya realizado de forma correcta (ver Figura \ref{fig:win}), o una animación de fracaso en el caso de que se produzca algún error en la ejecución del movimiento. Posteriormente, se presenta un esqueleto  en el que se muestran de color rojo las partes del cuerpo cuya colocación debe ser corregida, y en color verde las que se han utilizado de manera correcta (ver Figura \ref{fig:analisis_movimiento}). A demás, se visualizará una serie de indicaciones en forma de texto para que el alumno pueda corregir la posición errónea de una forma mas efectiva (ej. \textit{Gira el brazo izquierdo hacia atrás}).


\section{Conclusiones del desarrollo del proyecto}
A lo largo de este capitulo se ha logrado explicar los estudios y las implementaciones necesarias para este proyecto. La primera decisión fue elegir el paquete para \texttt{Unity} \texttt {Kinect v2 Examples with MS-SDK}, siendo este, un pilar importante para la compresión y entendiemiento del funcionamiento de \texttt{Kinect}. 

Los datos obtenidos del sensor de \texttt{kinect}, son extraídos para interpretarlos y mostrarlos a través de los \textit{cubeman}. Gracias a ello, se consiguió guardar y catalogar los movimientos del \textit{cubeman} para realizar comparaciones. El funcionamiento de los gestos que reconoce \texttt{Kinect} fueron una inspiración para la implementación de la comparación de movimientos.

Posteriormente, se diseñaron avatares con el programa \texttt{Fuse Character Creator} para sustituir a los \textit{cubeman} y dar una apariencia más realista a la aplicación. Con el objetivo de dar un toque más dinámico, se añadieron a los avatares unas animaciones de movimientos de capoeira, de modo que, se reproduzcan cuando no se detecte al usuario. Adicionalmente, para el \textit{feeback} de la comparación del movimiento, se añadieron también dos animaciones de victoria y derrota.

Para separar a los avatares se lograron diseñar dos escenarios. El primero simula un gimnasio dando la sensación al usuario de que está practicando, y el segundo escenario simula una isla tropical típica donde los expertos de capoeira practican. En el segundo escenario se mostrarán los movimiento que el usuario debe realizar.

Con el objetivo de completar la comparación de los movimientos, se logró implementar un proceso que realiza un análisis de cada parte del cuerpo. De esta manera, se contrasta con el movimiento a realizar y mostrará las correcciones oportunas que el usuario debe ejecutar.

Y por último, se consiguieron grabar movimientos de gente experta en capoeira, con el fin de catalogarlos y prepararlos para su ejecución.

%-------------------------------------------------------------------
%-------------------------------------------------------------------

