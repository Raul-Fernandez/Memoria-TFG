
%---------------------------------------------------------------------
%
%                          Capítulo 2
%
%---------------------------------------------------------------------



\chapter{Estado del arte}


%-------------------------------------------------------------------
\section{Captura de movimiento}

\label{cap2:sec:captura}


%-------------------------------------------------------------------


La captura de movimiento (abreviada \texttt{Mocap}, en inglés \textit{Motion Capture}) es el proceso por el cual el movimiento, ya sea de objetos, animales o mayormente personas, se traslada a un modelo digital 3D.

En la actualidad, esta técnica llamada \texttt{fotogrametría}, se utiliza en la industria del cine y de los videojuegos, ya que facilita mucho la labor de los animadores al realizar un modelado mas realista. En el cine se utiliza como mecanismo para almacenar los movimientos realizados por los actores, y poder animar los modelos digitales de los diferentes personajes que tenga el film. En cambio, en el sector de los videojuegos se utiliza para naturalizar los movimientos de los personajes. De ese modo se obtiene una mayor sensación de realismo. \citep{aleman2014solucion} \citep{menendez2015protocolo} \citep{mejias2014rotoscopia} \citep{wiki1}.



%-------------------------------------------------------------------
\section{Historia de la captura de movimiento}

%-------------------------------------------------------------------

\subsection{Precursores}

Ya en la antigua Grecia, Aristoteles (384-322 AC) escribió el libro \textit{``De Motu Animalium''} (Movimiento de los animales). Él no solo veía los cuerpos de los animales como sistemas mecánicos, sino que perseguía la idea de como diferenciar la realización de un movimiento y como poderlo hacer realmente, por lo que podría ser considerado el primer biomecánico de la historia.

Aproximadamente dos mil años después, Leonardo da Vinci (1452-1519) trató de describir algunos mecanismos que utiliza el cuerpo humano para poder desplazarse, como un humano puede saltar, caminar, mantenerse de pie, etc.

Como pionero en la edad moderna, Eadweard Muybridge (1830-1904) fué el primer fotógrafo capaz de diseccionar el movimiento humano y animal, a través de múltiples cámaras tomando varias fotografías para captar instantes seguidos en el tiempo. Este experimento llamado ``el caballo en movimiento'', (véase Figura \ref{fig:muybridgehorses}),  utilizó esta técnica de fotografía. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth, height=0.3\textheight]{Imagenes/Capitulos/2/MuybridgeHorses}
	\caption{El caballo en movimiento de Muybridge}
	\label{fig:muybridgehorses}
\end{figure}

\subsection{Nacimiento de la captura de movimiento}


%-----------OK---------------

En la década de los 70, cuando empezaba a surgir la posibilidad de realizar animaciones de personajes por ordenador, se conseguía naturalizar los movimientos mediante técnicas clásicas de diseño, como la técnica de rotoscopia. Esta técnica consiste en reemplazar los frames de una grabación real por dibujos calcados en cada frame. Los estudios \textit{Walt Disney Pictures} utilizaron esta técnica en la película de 1937 ``Blancanieves y los siete enanitos'', para animar a los personajes del príncipe y Blancanieves. 

Mientras, los laboratorios de biomecánica empezaban a usar los ordenadores como medio para analizar el movimiento humano. En la década de los 80, \texttt{Tom Calvert}, un profesor de kinesiología y ciencias de la computación en la universidad Simon Fraser (Canadá), incorporó potenciómetros a un cuerpo y la salida la usó para generar personajes animados por ordenador, con el objetivo de ser utilizados por estudios coreográficos y asistencia clínica para ayudar a pacientes con problemas de locomoción. 


A principios de los años 80, centros como el MIT (Massachusetts Institute of Technology) empezaron a realizar experimentos con dispositivos de seguimiento visual aplicados en el cuerpo humano. Mas tarde, empiezan a cobrar importancia los primeros sistemas de seguimiento visual como el \texttt{Op-Eye} y el \texttt{SelSpot}. Estos sistemas normalmente usaban pequeños marcadores adheridos al cuerpo (sección\ref{mocap_optica}) (Leds parpadeantes) con una serie de cámaras alrededor del espacio donde se realizaba la actividad.


En 1985, Jim Henson Productions (Organización de entretenimiento norteamericana) intentó crear versiones virtuales de sus personajes, pero no obtuvieron el éxito deseado, debido principalmente a la limitación de las capacidades de la tecnología en ese instante. Con los equipos 4D de Silicon Graphics y la perspicacia de Pacific Data Images (Productora de animación por ordenador), en 1988 los miembros de la compañía encontraron una solución viable para controlar las animaciones. Fueron capaces de regular la posición y los movimientos de la boca de un personaje a baja resolución y en tiempo real a través de la captura de movimiento de las manos de un actor con un aparato llamado Waldo, para su posterior interpretación en un ordenador. De esta manera surgió la primera marioneta virtual conocida como Waldo C. Graphic. 


En 1988, Brad deGraf y Wahrman desarrollaron \textit{Mike the Talking Head} de Silicon Graphics, capaz de mostrar las capacidades de sus nuevos equipos 4D en tiempo real. Mike estaba dirigido por un controlador que permitía controlar diferentes parámetros de la cara del personaje: como los ojos, boca, expresión y posición de la cabeza. El hardware de Silicon Graphics proporcionaba una interpolación en tiempo real entre las expresiones faciales y la geometría de la cabeza del personaje y del usuario. En el congreso de SIGGRAPH, Mike fue mostrado al público, donde se demostró que la tecnología \textit{mocap} estaba preparada para su explotación. 


Años mas tarde, en los 90, deGraf continuó investigando en solitario en el desarrollo de un sistema de animación en tiempo real conocido como ``Alive''. Para lograr animar un personaje interpretado con ``Alive'', deGraf desarrolló un dispositivo especial con cinco pistones, los cuales representaban los dedos de la mano de la persona que controlaba al personaje virtual a modo de titiritero.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\linewidth, height=0.3\textheight]{Imagenes/Capitulos/2/moxy_hiya}
	\caption{El perro generado por ordenador: Mozy}
	\label{fig:moxy_hiya}
\end{figure}

Con todo esto, deGraf pasó a formar parte de la compañía Colossal Pictures, donde animó a ``Moxy'' (véase Figura \ref{fig:moxy_hiya}):un perro generado por ordenador que presentaba un programa en Cartoon Network, mediante el sistema ``Alive''. ``Moxy'' es interpretado en tiempo real para publicidad, pero su uso en el programa era renderizado. Los movimientos del actor se capturaban mediante un sistema electromagnético con sensores en la cabeza, torso, manos y pies.




Tras estos avances, Pacific Data Images desarrolló un exoesqueleto de plástico, de modo que el actor se colocaría el traje con el objetivo de capturar los movimientos corporales: de la cabeza, pecho y brazos, a través de potenciómetros situados en la capa de plástico. De esta manera, los actores podían controlar los personajes virtuales mimetizando sus movimientos. Pese a que el traje se utilizó en varios proyectos, no se consiguieron los resultados esperados, ya que el ruido de los circuitos y el diseño inapropiado del traje no lo permitían. 

En torno a 1992, la empresa SimGraphics desarrolló un sistema de rastreo facial llamado \textit{Face Waldo}. Consiguieron capturar la mayor parte de los movimientos usando sensores adheridos a la barbilla, labios, mejillas, cejas y en el armazón del casco que llevaba el actor para su posterior aplicación en un personaje virtual en tiempo real. Este sistema logró ser novedoso ya que el actor podía manejar las expresiones faciales de un personaje a través de sus movimientos, logrando unos gestos mas naturales que los capturados anteriormente.

Lo que produjo un éxito mayúsculo con este proyecto fue la interpretación en tiempo real de Mario, el personaje principal de la saga de videojuegos \textit{Mario Bros}. Estaba controlado por un actor mediante \textit{Face Waldo}, Mario conseguía dialogar con los miembros de una conferencia, respondiendo a sus preguntas. A partir de ese momento, SimGraphics se centró en la animación en directo, desarrollando personajes para televisión y otros eventos en directo, mejorando la fiabilidad del sistema para el rastreo facial. 

Poco después, en el congreso de SIGGRAPH en 1993, la empresa Acclaim\footnote{Empresa encargada del desarrollo, publicación, venta y distribución de videojuegos para diferentes compañias (Sega, Nintendo, Sony, Microsoft...)} asombró al público con animaciones realistas y complejas de dos personajes animados en su totalidad mediante captura de movimientos. En los años anteriores, habían desarrollado de forma encubierta un sistema de rastreo óptico de alta definición, muy superior a los citados anteriormente, capaz de seguir 100 marcadores de forma simultanea en tiempo real.

De forma gradual, la técnica \textit{mocap} se fue expandiendo entre las empresas desarrolladoras de sistemas de captura de datos, con el objetivo de crear productos y métodos que albergasen nuevos sectores empresariales. Gracias al desarrollo previo, en 1995 hizo su aparición el primer videojuego en el que se aplicó esta técnica de forma extensa, se trataba de Highlander: The Last of the Macleods de la compañía Atari, el cual marcó el inicio del desarrollo tecnológico sobre videojuegos y productos audiovisuales. 

A lo largo de los años, fueron apareciendo largometrajes que mostraban como la captura de movimientos ha evolucionando día tras día y con una gran proyección de futuro, ha pasando de ser algo que utilizaban de forma esporádica algunos personajes, a ser indispensable en cualquier producción. Como por ejemplo en los \textit{films}: Jar Jar Binks en la saga de \textit{Star Wars}, el personaje de La Momia, Gollum en la trilogía de El Señor de los Anillos y de El Hobbit, Final Fantasy: La fuerza interior, Avatar, etc. También existen videojuegos recientes que utilizan esta tecnología en su desarrollo: The Last os Us, Beyond: Two Souls, la saga Uncharted, Until Dawn, L.A. Noire, etc.


%----------OK----------

%-------------------------------------------------------------------



\section{Métodos de captura de movimiento}

En la actualidad existen numerosos sistemas para la captura de movimientos. Dependiendo de las necesidades de la producción, ya estén relacionados con el presupuesto disponible, así como las posiciones, velocidades, impulsos del actor o el nivel de realismo al que se quiera llegar. Atendiendo a su tecnología, se pueden encontrar los diferentes métodos que se desarrollan a continuación.

%-------------------------------------------------------------------

\subsection{Captura de movimiento mecánica}

En el proceso de captura de movimiento mecánica (véase Figura \ref{fig:mocapmecanica}), el actor viste unos trajes especiales adaptables al cuerpo humano. En su mayoría, estos trajes están compuestos por estructuras rígidas con barras metálicas o plásticas, unidas mediante potenciómetros colocados en las principales articulaciones. Los potenciómetros se componen de un elemento deslizante acoplado a una resistencia, la cual produce una variación de tensión que puede medirse para conocer el grado de apertura de la articulación donde se encuentre acoplado. Los sensores que recogen la información pueden transmitirla mediante cables, pero normalmente lo hacen con radiofrecuencia.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth, height=0.26\textheight]{Imagenes/Capitulos/2/mocap_mecanica}
	\caption{Sistema de captura de movimiento mecánico}
	\label{fig:mocapmecanica}
\end{figure}

Estos sistemas tienen el problema de que son incapaces de medir translaciones globales. Pueden medir posiciones relativas de los miembros, pero no como se desplaza el actor por el escenario. Además, el único valor que utilizan para medir es el grado de apertura, no teniendo en cuenta rotaciones complejas que poseen las articulaciones humanas, como es el caso de los hombros, cadera, tobillos, etc. También tienen el inconveniente de ser pesados, restringir el movimiento del actor y su corto tiempo de vida. En cambio, tienen la ventaja de tener un coste relativamente bajo (en torno a 17.000 y 50.000 \euro), capaz de registrar los movimientos del actor en tiempo real con un alcance mayúsculo. 


\subsection{Captura de movimiento electromagnética}


Los sistemas de captura de movimiento electromagnética (véase Figura \ref{fig:mocapelectromagnetica}), están formados por sensores creados por tres espirales ortogonales que miden el flujo magnético, determinando tanto la posición como la orientación del sensor. Un transmisor genera un campo electromagnético de baja frecuencia que los receptores detectan y transmiten a la unidad electrónica de control, donde se filtra y amplifica. A continuación, los datos se envían a un ordenador central, donde se deduce la orientación y posición de todos los sensores del escenario.

Un sistema magnético estándar consta de 18 sensores, una unidad de control electrónica y un software para el procesamiento. En cambio, un sistema de última generación puede tener hasta 90 sensores capaces de capturar hasta 144 muestras por segundo, teniendo un coste medio (en torno a 4.000 y 11.000 \euro).

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth, height=0.3\textheight]{Imagenes/Capitulos/2/mocap_electromagnetica}
	\caption{Sistema de captura de movimiento electromagnético}
	\label{fig:mocapelectromagnetica}
\end{figure}
\vspace{0.2cm}
Existen dos tipos de rastreadores electromagnéticos:

\begin{itemize}
	\item \textit{Flock of Birds de
		Ascension Technology Corporation}: usa pulsos magnéticos cuadrados.
	\item   \textit{Patriot de Polhemus}: usa campos magnéticos sinusoidales.
\end{itemize}

Ambos sistemas tienen el inconveniente de producir interferencias con materiales metálicos debido a su conductividad, ya que se crean campos magnéticos que interfieren con el campo magnético del emisor. De ese modo, se trata de un sistema difícil de transportar a diferentes escenarios. El proceso de captura no es en tiempo real, aunque se aproxima bastante, pese a que tiene un número de capturas por segundo demasiado bajo. Como punto a favor, es mas fácil procesar los datos que en otros sistemas \textit{mocap}, ya que los datos obtenidos están en relación con la posición del actor.

\subsection{Captura de movimiento óptica}
\label{mocap_optica}

Los sistemas ópticos emplean los datos recogidos por sensores de imagen para obtener la posición de un elemento en el espacio, utilizando indicadores (en inglés \textit{markers}) pegados al cuerpo del actor, aunque los sistemas modernos permiten recoger los datos rastreando la superficie de forma dinámica. 

Estos sistemas permiten la grabación en tiempo real, ya que utilizan un ordenador que recibe la entrada de una o mas cámaras digitales CCD (Charge-coupled device) sincronizadas produciendo proyecciones simultáneas. Habitualmente se utilizan entorno a 4 o 32 cámaras, siempre y cuando no se añadan de forma innecesarias, ya que complicarían el procesamiento de la información.

Las cámaras utilizadas en este tipo de sistemas tienen una velocidad de captura de entre 30 y 1.000 fotogramas por segundo. Estos sistemas se deben calibrar mediante el rastreo de un objeto visible, de modo que se calcule la posición de cada cámara respecto de ese punto, en el caso de que una cámara se mueva, será necesario recalibrar el sistema.

Existen varios clases de sensores para este tipo de captura de movimiento:

\subsubsection{Indicadores activos}

Este sistema está compuesto por leds que emiten su propia luz determinando la posición del actor, de esta manera se consigue aumentar la distancia a la que se puede desplazar el artista (véase Figura \ref{fig:mocapindicadoresactivos}). La posición de los marcadores se determina iluminando uno o varios indicadores, de manera sincrónica a las cámaras en cada instante de tiempo, a una frecuencia de muestreo muy alta. De modo que los indicadores deben estar sincronizados con todas la cámaras para realizar una sola captura en cada iluminación.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth, height=0.3\textheight]{Imagenes/Capitulos/2/mocap_indicadoresactivos}
	\caption{Sistema de captura de movimiento óptico con indicadores activos}
	\label{fig:mocapindicadoresactivos}
\end{figure}

\subsubsection{Indicadores pasivos}

Estos indicadores véase Figura \ref{fig:mocapindicadorespasivos}), se tratan de bolas de goma recubiertas de un material reflectante que se adhieren al traje del actor en puntos estratégicos. De esta forma, la luz que reflejan se origina cerca de las cámaras, siendo recogida por estas. 


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth, height=0.3\textheight]{Imagenes/Capitulos/2/mocap_indicadorespasivos}
	\caption{Sistema de captura de movimiento óptico con indicadores pasivos}
	\label{fig:mocapindicadorespasivos}
\end{figure}

Este tipo de sistemas pueden capturar un gran número de marcadores a una frecuencia de muestreo de hasta 2000 fotogramas por segundo. Se suelen utilizar principalmente para el registro de movimiento facial. El precio de estos marcadores oscila entre 17.000 y 75.000 \euro.

\subsubsection{Indicadores activos modulados en el tiempo}

Utilizando luz estroboscópica, se mejora el sistema respecto a los indicadores activos estándar, y mediante la iluminación de manera grupal se determina la identidad de cada marcador a través de la frecuencia de destello. De esta manera, se consiguen frecuencias de captura mayores, con el inconveniente de aumentar la carga del sistema. Este tipo de marcadores permiten observar el resultado en tiempo real, ya que cada indincador es único, eliminando el problema del intercambio de marcadores. Además, este sistema permite su utilización bajo la luz directa del sol, sin que se produzcan interferencias.

Existen sistemas de captura de movimiento compuestos por ocho cámaras de 12 \textit{megapixeles} capaces de capturar hasta 480 fotogramas por segundo. Con un precio inferior a los 38.000 \euro. 


\subsubsection{Indicadores semipasivos imperceptibles}


A diferencia de los sistemas anteriores, en este caso, son los propios indicadores emisores de luz led los que detectan su propia posición y orientación. Se trata de marcadores que determinan la incidencia de iluminación, con un número ilimitado de etiquetas fotosensibles. Permitiendo colocarse en la ropa u otros objetos, además de trabajar bajo la luz solar. Considerando que no se utilizan cámaras de alta frecuencia , se reduce de forma considerable el tráfico de datos. Por lo tanto, son ideales para la captura de movimientos en tiempo real.


\subsubsection{Sin marcadores}


Se trata de un sistema en el que no se requiere el uso de trajes especiales para el seguimiento de los movimientos de los actores. Se utilizan algoritmos que permiten identificar la silueta humana mediante el análisis de imágenes, identificando sus formas y descomponiendolas en segmentos para realizar el seguimiento de sus movimientos. Estos sistemas tienen la dificultad de capturar movimientos sutiles, como los realizados con los dedos o la cara.


\subsection{Captura de movimiento mediante fibra óptica}


Inicialmente, este medio de transmisión se empleó para el desarrollo de unos guantes capaces de capturar el movimiento de los dedos, pero en la actualidad, se han creado trajes idóneos para captar cualquier parte del cuerpo. Con el objetivo de registrar los movimientos, se fijan sensores de fibra óptica flexibles, consiguiendo atenuar la luz transmitida, y así, medir las rotaciones de las articulaciones. Estos sensores no son capaces de medir la posición del actor en el escenario, sino que el sistema calcula la posición de las extremidades capturadas. 


\subsection{Captura de movimiento mediante ultrasonidos}

Este sistema utiliza emisores que generan pulsos ultrasónicos (imperceptible por el ser humano) capturados por uno o varios receptores (a modo de radar), permitiendo averiguar la posición del emisor en el escenario, incluso en algunos casos, su orientación. El inconveniente de esta tecnología se debe a que los emisores son demasiado voluminosos, siendo incapaces de capturar movimientos bruscos de una forma correcta. Aunque en comparación con otros sistema de captura de movimiento, el precio supone una gran ventaja, teniendo un coste de 2500 \euro.

\subsection{Captura de movimiento mediante sistemas inerciales}


Con el objetivo de capturar el movimiento, los sistemas inerciales emplean sensores, como giroscopios y acelerómetros, con el propósito de obtener información sobre la velocidad angular y la aceleración del sensor.  La información obtenida de los sensores se transmite a un ordenador, donde se puede observar el movimiento capturado sobre una figura ya animada. Este tipo de sistemas no utiliza mecanismos externos como cámaras; y como en el caso de los sistemas ópticos, cuantos más sensores se utilicen, más real será el movimiento capturado, teniendo unos grandes rangos de captura. 

El sistema de Nintendo (Wiimote) utiliza esta técnica, no obstante, para la captura de movimientos se utilizan trajes especiales con otros sensores mas precisos, con un precio que varía entre 22.000 y 71.000 \euro.


\subsection{Captura de movimiento ocular}

Estos sistemas utilizan la combinación del seguimiento de los ojos con el de la cabeza, obtiniendo unas líneas exactas de la vista, mientras que el usuario es capaz de moverse libremente. De este modo, permite a los atletas, pacientes y otros usuarios desempeñar sus tareas de una forma correcta, sin ningún tipo de impedimento.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth, height=0.32\textheight]{Imagenes/Capitulos/2/ETG-2w}
	\caption{Gafa ETG-2w usada para la captura de movimiento ocular}
	\label{fig:etg-2w}
\end{figure}


Como ejemplo de investigación en esta tecnología, la empresa SMI (Senso Motoric Instruments)\footnote{https://www.smivision.com/eye-tracking/product/eye-tracking-glasses/} ha desarrollado una gafa (véase Figura \ref{fig:etg-2w}) que permite el seguimiento de los ojos y combinado con la cámara, detecta el punto exacto donde está detenienda la mirada. Soportando el acceso de datos en tiempo real y el control de usuario a través de una conexión inalámbrica. 


\section{Métodos de captura de movimiento en los videojuegos }

En la actualidad, gracias a la necesidad de crear unos personajes con gestos y movimientos mas realistas, el sector de los videojuegos ha conseguido que la captura de movimiento se convierta en una herramienta esencial, ya que permite una mayor inmersión en los videojuegos. Llegando a ser interpretados en la mayoría de juegos deportivos, por jugadores profesionales.

En consecuencia, las principales empresas de videojuegos como Nintendo, Sony y Microsoft, han desarrollado los siguientes sistemas capaces de capturar movimientos.

\subsection{Nintendo, Wii Remote}

En el año 2006, Nintendo lanzó Wii \citep{NintendoWii}, perteneciente a la séptima generación de videoconsolas, sucesora directa de Nintendo GameCube y compitió con la Xbox 360 de Microsoft y la PlayStation 3 de Sony. La compañia Nintendo afirmó que Wii (véase Figura \ref{fig:wiiremote}) estaba destinada a un abanico de consumidores mas amplico a diferencia de sus rivales. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth, height=0.3\textheight]{Imagenes/Capitulos/2/wii_remote}
	\caption{Mando inalámbrico Wii Remote}
	\label{fig:wiiremote}
\end{figure}



La característica más distintiva de la consola, es el mando inalámbrico Wii Remote. Se trata de un dispositivo inalambrico, capaz de detectar la aceleración en un plano tridimensional mediante la utilización de un acelerometro ofrece la posibilidad de apuntar y señalar, determinando los movimientos en un plano tridimensional mediante la utilización de un acelerometro. Además cuenta con un sensor óptico, lo que permite determinar el lugar donde el mando Wii Remote está apuntando. 

A diferencia de un mando a distancia tradicional, este sistema detecta la luz led que emite la barra de sensores de la consola (véase Figura \ref{fig:barrasensor}). Tiene un tamaño aproximado de 20 cm de longitud y cuanta con diez leds infrarrojos, cinco en cada extremo de la barra. Para un correcto funcionamiento, no es necesario señalar directamente a la barra sensor, pero en caso contrario, perturbaría la capacidad de detección debido al limitado ángulo de visión. La barra sensor emite desde cada uno de los extremos, unos puntos de luz que permite al Wii Remote ser localizado. A partir de estas dos distancias, el procesador de la videoconsola Wii determina la distancia entre el Wiimote y la barra de sensores utilizando la triangulación. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth, height=0.25\textheight]{Imagenes/Capitulos/2/barra_sensor}
	\caption{Barra sensor de la videoconsola Wii}
	\label{fig:barrasensor}
\end{figure}



Los movimientos realizados con Wii Remote, permiten al jugador imitar las acciones reales de juego, como mover una espada, lanzar una bola de fuego, disparar una pistola, etc; en lugar de pulsar solo los botones.


\subsection{Sony, PlayStation Move}

Como consecuencia de los buenos resultados obtenidos por Nintendo, Sony sacó al mercado en 2010, PlayStation Move \citep{PlayStationMove}, un sistema de control de movimientos mediante marcadores activos, compatible con las videoconsolas PS3 y PS4 (véase Figura \ref{fig:playstation-move}). Este sistema incorpora un giroscopio, ya que ningúna tecnología de captura de movimientos mediante marcadores, puede determinar si se han producido giros sin realizar una triangulación.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth, height=0.28\textheight]{Imagenes/Capitulos/2/playstation-move}
	\caption{Dispositivo PlayStation Move}
	\label{fig:playstation-move}
\end{figure}

Estas videoconsolas utilizan una camara denominada PlayStation Eye \citep{PlayStationEye} que detecta el color que toma la esfera del dispositivo PlayStation Move, determinando de este modo su posición.
Esta camara dispone de dos lente, una de ellas realiza la función de camara web y la otra activa la captura de movimientos. (véase Figura \ref{fig:playstation-eye}) 

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth, height=0.28\textheight]{Imagenes/Capitulos/2/playstation-eye}
	\caption{Dispositivo PlayStation Eye}
	\label{fig:playstation-eye}
\end{figure}

El principal inconveniente de este sistema, es la luz y los colores de fondo. Ya que, se vuelve inútil teniendo una luz de fondo del mismo color que el dispositivo PlayStation Move, perdiendo por completo la posición de los marcadores. En la actualidad, es el sistema con menor estabilidad en la captura de movimientos en los videojuegos.


\subsection{Microsoft, Kinect}
\label{Kinect}

Por otra parte, en 2010 Microsoft desarrolló \texttt{Kinect}\citep{Kinectv2} para Xbox 360, en sus inicios conocido como \textit{Project Natal} (véase Figura fig:kinectv2). Después de unos años, Microsoft ofreció la posibilidad de conectar \texttt{Kinect} por medio de ordenadores o tabletas, con el sistema operativo Windows 8 o superior, mediante un adaptador \citep{adaptadorKinect} con una conexión usb 3.0. 

El dispositivo \texttt{Kinect} es un periférico para videojuegos que prescinde de mandos gracias a un sensor de detección de movimientos. Este sistema reconoce el rostro, la voz, los movimientos y gestos de los jugadores, mediante una cámara conectada a la videoconsola, el ordenador o \textit{tablet}. 


Se trata de una barra horizontal conectada a una plataforma diseñada para mantenerse en una posición horizontal. En su interior contiene un hardware compuesto por una cámara RGB, un sensor de profundidad, el proyector de luz infrarroja, un micrófono bidireccional, un firmware y un procesador que utiliza algoritmos para procesar las imágenes tridimensionales. De forma conjunta capturan el movimiento, además de ofrecer un reconocimiento facial y de voz. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth, height=0.28\textheight]{Imagenes/Capitulos/2/kinectv2}
	\caption{Dispositivo Kinect v2}
	\label{fig:kinectv2}
\end{figure}

\vspace{0.8cm}

En 2013, Microsoft anunció su próxima consola Xbox One y el nuevo sensor de \texttt{Kinect} que incluía mejoras sustanciales respecto a la versión anterior. A continuación se destacan las más significativas a nivel de desarrollo. \citep{HardwareKinect}

\begin{itemize}
	\item \textbf{Mayor campo de visión y un seguimiento mejorado del cuerpo}
	
	\begin{itemize}
		
		\item Con un campo de visión de 70º en horizontal y 60º en vertical. La versión inicial disponía de 57º y 43º respectivamente.
		
		\item Esta nueva versión, permite detectar hasta seis jugadores de forma simultanea con 25 articulaciones por persona dentro de un mismo campo de visión. La versión anterior solo podía detectar dos jugadores y 20 articulaciones.
		
		\item Como desventaja, destacar la carencia de motor de inclinación en esta nueva versión de \textit{Kinect}.
	\end{itemize}
	
		\item  \textbf{Mayor resolución con mas detalle}
		
		\begin{itemize}
			
			\item Cámara a color capaz de realizar vídeos con una resolución Full HD de 1920 x 1080 ppp. La versión inicial disponía de 640 x 480 ppp.
			
			\item Detecta de una manera más precisa el entorno.
			
			\item Capacidad de diferenciar la orientación del cuerpo incluyendo sus manos y dedos.
			
			\item El \textit{face tracking} tiene mucho más detalle,  permitiendo captar los gestos de la cara.
			
			\item Mayor calidad de imagen.
		\end{itemize}
	
	
	\item \textbf{Mejora el rango de profundidad del sensor}
	
	Se incrementa el rango de actuación, pasando de 0,5 a 4,5 metros.
	
	\item \textbf{Aumento de la velocidad en el puerto USB 3.0}
	
	La velocidad de la comunicación con el ordenador se transmite mas rápido, disminuyendo la latencia del sensor, pasando de 90 ms a 60 ms.
		
	\item \textbf{Mejora en la captación de sonidos}
	
	Esta nueva versión de \texttt{Kinect} incluye una gran mejora en cuanto al reconocimiento de voz. De modo que eliminando los ruidos de ambiente, permite captar instrucciones sonoras con mayor detalle.
	
	\item \textbf{Captación de movimientos a oscuras}
	
	
	Nuevas funciones de infrarrojos (IR), capaces de reconocer y captar los movimientos aunque la sala este a oscuras. Genera una vista independiente de la iluminación
	
	
\end{itemize}

\texttt{Kinect} tiene dos funcionalidades principales, generar un mapa 3D de la imagen que capta la cámara y realizar un reconocimiento humano en movimiento a partir de diferentes segmentos del cuerpo, además de un esquema en escala de grises del rostro. El periférico, transmite una luz infrarroja a través del escenario, lo que permite conocer el tiempo que tarda la luz en ser reflejada por los objetos. El sistema actúa como un sonar, determinando el tiempo que tarda en reflejarse la luz, se establece la distancia a la que se encuentran los objetos en tiempo real. 



\vspace{0.7cm}
Como base para el estudio de la captura de movimientos y las tecnologías disponibles en este ámbito, se han realizado diferentes consultas a los siguientes proyectos: \citep{aleman2014solucion} \citep{menendez2015protocolo} \citep{mejias2014rotoscopia}


%Y también ponemos el acrónimo \ac{CVS} para que no cruja.

%Ten en cuenta que si no quieres acrónimos (o no quieres que te falle la compilación en ``release'' mientras no tengas ninguno) basta con que no definas la constante \verb+\acronimosEnRelease+ (en \texttt{config.tex}).



\section{Trabajo relacionado}
Para la realización de este proyecto se han revisado trabajos anteriores en el área de los \textit{Reactive Virtual Trainers}. En este apartado se describirán los análisis de esos proyectos, y de este modo, poder aclarar y enfocar el desarrollo de este trabajo.

\subsection{Captura de movimiento en la danza}
Uno de los campos en donde la captura de movimiento aparece es en la danza, y un claro ejemplo es \citep{Kyan:2015:ABD:2753829.2735951}. En este artículo se describe una forma de evaluar y visualizar en tiempo real, los movimientos de la danza de ballet. Para desempeñar esa tarea utilizan como recurso la tecnología de captura de movimiento \texttt{kinect}, y gracias a ella, registran los movimientos de bailarines profesionales, de modo que , sean una base para las comparaciones de movimientos. Estos, a su vez , son representados como un \textit{espacio de posturas} en forma de trayectorias de gestos. La evaluación de la coreografía empezará cuando detecte al bailarín aficionado y con el fin de proporcionar una puntuación para cada coreografía,
se compara la posición alineada y velocidad del bailarín aficionado con las correspondientes del bailarín profesional.


\subsection{Captura de movimiento en artes marciales}
Otros de los campos donde es útil la captura de movimiento ,ya que es necesario la repetición para lograr entender y dominar las técnicas, son en las artes marciales. En este proyecto de máster \citep{Keerthy:Thesis:2012}  se diseña un maestro virtual de Kung fu con el dispositivo de \texttt{Kinect}. Previamente se graban las técnicas del maestro en el arte marcial , para realizar futuras comparaciones con usuarios aficionados que quieran adentrarse y aprender en el mundo del Kung fu. Aunque existen muchos algoritmos de comparación, en este trabajo se ha elegido, el algoritmo
\textit{Dynamic Time Warping} , que utiliza la fórmula  distancia euclidea. Una de las principales ventajas del algoritmo \textit{Dynamic Time Warping} es, superar los problemas de análisis de movimiento en velocidad y tiempo. La distancia euclidiana se define como la distancia entre dos puntos de un espacio euclídeo, la cual se deduce a partir del teorema de Pitágoras.\\

La distancia euclidiana$(d_e)$ de dos puntos P(X,Y,Z), Q(x,y,z) viene definida por :
$$d_e(P,Q)=\sqrt{(X_i+x_i)^2 + (Y_i+y_i)^2 +(Z_i+x_i)^2 }$$

La fórmula se ejecuta en un espacio de tres dimensiones.\\

Dentro del mismo ámbito de captura de movimiento en artes marciales, se encuentra este proyecto\citep{chua2003training}, el cual desarrolla un entrenador virtual de Tai Chi. La diferencia con el proyecto de  \citep{Keerthy:Thesis:2012} se refleja en la forma de  comparar el movimiento, debido a que coloca los diferentes movimientos del profesor alrededor del estudiante, de este modo, le ofrece la opción de superponer su cuerpo directamente sobre el movimiento del profesor virtual para efectuarlo correctamente. 

\subsection{Captura de movimiento en actividades físicas}
Uno de los factores importantes en la ejecución de actividades físicas es el evitar lesión por mala práctica. En esta tesis \citep{Staab:Thesis:2014} implementan un entrenador virtual para promover la actividad saludable , y enseñar de una forma correcta, la realización de las ejercicios para prevenir lesiones. Los movimientos del entrenador virtual son generados a partir de la clasificación y el análisis de ejercicios previamente grabados, creando así, un modelo estadístico de cada actividad. Cuando el usuario realiza la tarea se proporcionado un porcentaje de acierto para la posición, una indicación para su corrección y los grados de rotación que se deben de aplicar. Aunque, realiza una corrección precisa, tiene una decadencia cuando los movimientos son giros sobre el mismo eje.

El siguiente proyecto denominado \texttt{OnlineGym} \citep{Paredes2014} , es un  trabajo basado en plataformas de mundos virtuales 3D que permite a los usuarios interactuar mediante el uso de un dispositivo de captura de movimiento, en concreto con \texttt{kinect}. Este escenario proporciona la experiencia de una participación conjunta en una sesión de gimnasia grupal. El proyecto está dirigido a usuarios de edad avanzada, que tal vez no puedan participar en
sesiones regulares de entrenamiento fuera de sus hogares. Para activar las habilidades motoras y de socialización, se realizan sesiones de \textit{fitness} en grupo para contribuir a su bienestar físico y mental. 

Otro proyecto que falta por mencionar es el \citep{Ruttkay2008}, el cual desarrolla un entrenador virtual mejorado, que además de presentar los ejercicios físicos a realizar, proporciona un \textit{feedback} en el momento apropiado. Gracias a esta faceta, el \textit{Intelligent Virtual Agent} (IVA) será capaz de introducir y estructurar los diferentes ejercicios. El entrador virtual tendrá una motorización del pulso asociado al usuario para ajustar el ritmo del ejercicio.

\subsection{Captura de movimiento en rehabilitación}
Un punto fuerte para la utilización de la captura de movimiento sería  aplicarla para ayudar a la gente con lesiones, y de este modo, realizar terapia de rehabilitación. Con esta idea se ha desarrollado el proyecto \citep{li2014development}, que elabora un entrador virtual para el uso de 
fisioterapeutas y pacientes en programas de fisioterapia con ejercicios físicos. Permite al terapeuta adaptar los ejercicios a la necesidades de cada paciente de un modo individual. Los pacientes pueden escoger entre diferentes programas y seguir un avatar de entrenamiento, a su vez, los movimientos que simulan los avatares son grabados previamente en función de las necesidades del paciente. Uno de los puntos que sacan en claro en este proyecto es, que los juegos de ordenador han demostrado el potencial para mejorar el apego a la rehabilitación por parte de los pacientes. Del mismo modo, se encuentra que el \textit{feedback} visual ofrecido a los pacientes le hace involucrarse de manera más efectiva con las terapias.

Otro proyecto con una terapia mas especificas es \citep{sin2013additional}, que estudia los efectos de un entrenador virtual para los paciente con hemiplejía\footnote{Parálisis de un lado del cuerpo causada por una lesión cerebral o de la médula espinal.}, haciendo énfasis en la función de las extremidades superiores, incluyendo el rango de movimiento, la función motora y la destreza manual. El grupo de usuarios que padecen esta parálisis participaron en diversas pruebas, en las que se utilizaba la tecnología implementada con \texttt{Nintendo Wii} y la tecnología de captura de movimiento de \texttt{Xbox} con \texttt{Kinect} entre otras. Las pruebas se centraban en juegos que utilizaban movimientos que afectaban las extremidades superiores. Los resultados de los ensayos demuestran una mejoría significativa de los pacientes que realizaron la prueba con la tecnología \texttt{kinect}, esto es debido, a que pueden desempeñar toda la tarea sin tener que sujetar un control remoto como pasa en \texttt{Nintendo Wii}. Siendo este, un factor añadido para realizar un movimiento con mayor amplitud o ejecutar mas cantidad de movimientos.
% Variable local para emacs, para  que encuentre el fichero maestro de
% compilación y funcionen mejor algunas teclas rápidas de AucTeX
%%%
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../Tesis.tex"
%%% End:
